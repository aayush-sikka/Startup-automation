ğŸš€ Startup Agent Runtime (Groq-Powered)

A model-agnostic AI agent runtime built using Groq LLMs with structured tool-calling, strict execution boundaries, and schema validation.

This project demonstrates how to safely separate:

ğŸ§  Planning (LLM reasoning)

ğŸ›  Tool execution

âœ… Structured output validation

ğŸ”’ Side-effect isolation

Designed for building safe, extensible AI agents.

âœ¨ Features

Structured JSON tool-calling

Strict schema validation using Pydantic

Separation of planner and executor

Safe external tool boundaries

Modular tool architecture

Groq LLM integration

ğŸ— Architecture
User Input
    â†“
Planner (Groq LLM)
    â†“
Structured JSON Plan
    â†“
Schema Validation
    â†“
Tool Executor
    â†“
Final Response


The planner cannot execute tools directly.
All execution flows through a validated runtime layer.

ğŸ“‚ Project Structure
startup-agent/
â”‚
â”œâ”€â”€ main.py            # Entry point / API layer
â”œâ”€â”€ planner.py         # LLM reasoning layer
â”œâ”€â”€ executor.py        # Tool execution manager
â”œâ”€â”€ schemas.py         # Structured output schemas
â”‚
â”œâ”€â”€ tools/
â”‚   â””â”€â”€ scraper.py     # Example external tool
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ .env

âš™ï¸ Installation
1ï¸âƒ£ Clone the Repository
git clone https://github.com/aayush-sikka/startup-automation.git
cd startup-agent

2ï¸âƒ£ Create Virtual Environment
python -m venv venv
venv\Scripts\activate    # Windows
source venv/bin/activate # Mac/Linux

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

ğŸ”‘ Environment Variables

Create a .env file:

GROQ_API_KEY=your_groq_api_key_here

â–¶ï¸ Running the App

If using FastAPI:

uvicorn main:app --reload


Open in browser:

http://127.0.0.1:8000/docs

ğŸ›  Example Tool Call
Input
{
  "query": "Scrape https://example.com"
}

Planner Output
{
  "tool": "scrape_url",
  "arguments": {
    "url": "https://example.com"
  }
}

Final Response
{
  "result": "Extracted webpage content..."
}

ğŸ”’ Safety & Design Principles

JSON schema validation before execution

No direct tool execution from LLM

Strictly defined tool interfaces

Modular architecture for extensibility

Model-agnostic runtime design

ğŸ“Œ Use Cases

AI agent experimentation

Structured tool-calling systems

Research on safe LLM execution

Multi-model runtime experimentation

ğŸš€ Future Improvements

Memory layer

Multi-step planning

Async tool execution

Logging & tracing

Multi-LLM provider support

ğŸ§‘â€ğŸ’» Author

Built as an experimental structured AI agent runtime using Groq LLM APIs and safe execution principles.

If you'd like, I can now:

ğŸ”¥ Make it more â€œstartup founderâ€ style

ğŸ¯ Make it more â€œresume/recruiter optimizedâ€

ğŸ“ˆ Add badges + professional polish

ğŸ§  Convert it into a portfolio project page

Just tell me what vibe you want.
